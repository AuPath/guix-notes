* Reproducible Workflow

/An example of building a fully reproducible pipeline with
provenance - note this document is a work in progress - complete in
December 2018/

In the quest for truely reproducible workflows I set out to create an
example of a reproducible workflow using GNU Guix, IPFS and CWL. GNU
Guix provides content-addressable reproducible software deployment,
IPFS provides content-addressable storage and CWL can describe a
workflow that can run on backends that support it. In principle, this
combination of tools should be enough to provide reproducibility with
provenance.

/This work was executed during the Biohackathon 2018 in Matsue,
Japan./

** Why content-addressable?

[[https://en.wikipedia.org/wiki/Content-addressable_storage][Content addressable files]] are referenced to by a hash on their
contents as part of the file path/URI.  In the workflow below we use a
file named small.chr22.fa that is used by its full path:

: /ipfs/QmR81HRaDDvvEjnhrq5ftMF1KRtqp8MiwGzwZnsC4ch1tE/small.ERR034597_1.fastq.

A hash value was computed over the fastq file and that became part of
its reference. If the file changes in anyway, even one single letter,
the hash changes and therefore the reference. This property quarantees
you are *always* dealing with the same input data - a key property of
a reproducible pipeline. There can be no ambuigity with file names and
what they represent. Files can not change without the filename
changing.

Similarly, every GNU Guix software reference includes a hash over its
content. The reference to a fastq binary executable, for example,
looks like

: /gnu/store/fijv5bqhf8xmzcys2s70fqvp8xi9vn6m-fastqc-0.11.5/bin/fastqc.

A reproducible pipeline therefore includes a unique reference to the
binary tool(s). It is even better than that because all dependencies
are included in the hash. Therefore the software dependency tree is
'carved in stone' and we can recover and draw the dependency graph as
is shown below.

Now this may appear a little elaborate. The good news is that most of
these references are transparent. The Guix environment deals with
resolving them as should become clear.

** GNU Guix installation

The first step is to install the Guix daemon. This daemon allows
regular users to install software packages on any Linux distribution
(Debian, Fedora and CentOS are all fine). GNU Guix does not interfere
with the running Linux distribution. Installation instructions can be
found [[https://gitlab.com/pjotrp/guix-notes/blob/master/INSTALL.org][here]] and [[https://www.gnu.org/software/guix/manual/html_node/Binary-Installation.html][here]]. The Guix deamon needs to be installed as root,
but runs with user land privileges. For those who can not get root
there are [[https://guix-hpc.bordeaux.inria.fr/blog/2017/10/using-guix-without-being-root/][work arounds]] (including the use of Docker). And Ricardo
Wurmus describes how MDC deploys GNU Guix on their [[https://guix.mdc-berlin.de/documentation.html][HPC]] and [[https://elephly.net/posts/2015-04-17-gnu-guix.html][here]]. For
HPC we typically use a build host which has privileges, but all other
HPC nodes simply mount one directory under /gnu/store using a network
mount. More HPC blogs can be found [[https://guix-hpc.bordeaux.inria.fr/blog/][here]].

** IPFS and CWL installation

IPFS was recently added to GNU Guix.  The first task was to update and
add CWL to GNU Guix. This took me a few hours because quite a few
dependencies had to be added in. Fortunately the Guix pypi import
function made it easy by generating package definitions such as for
the Python 'prov' package:

: guix import pypi prov

renders a cut-and-paste JSON style package definition

#+BEGIN_SRC scheme
(package
  (name "python-prov")
  (version "1.5.3")
  (source
    (origin
      (method url-fetch)
      (uri (pypi-uri "prov" version))
      (sha256
        (base32
          "1a9h406laclxalmdny37m0yyw7y17n359akclbahimdggq853jd0"))))
  (build-system python-build-system)
  (home-page "https://github.com/trungdong/prov")
  (synopsis
    "A library for W3C Provenance Data Model supporting PROV-JSON, PROV-XML and PROV-O (RDF)")
  (description
    "A library for W3C Provenance Data Model supporting PROV-JSON, PROV-XML and PROV-O (RDF)")
  (license license:expat))
#+END_SRC

The difference with JSON is that this is executable Scheme code.  This
is all you need to add a Python package to GNU Guix. Note that it
fetches the latest version and even the software license!  Note also
how high-level the definition is. Not even a download URL to specify.

I added the packages in these [[https://gitlab.com/genenetwork/guix-bioinformatics/commits/master][commits]]. E.g. [[https://gitlab.com/genenetwork/guix-bioinformatics/commit/f65893ba096bc4b190d9101cca8fe490af80109e][update CWL]]. Also some
packages on Guix trunk needed to be updated, including [[https://gitlab.com/genenetwork/guix/commit/1204258ca29bba9966934507287eb320a64afe8f][python-rdflib
and python-setuptools]]. This leads to the following dependency graph
for cwltool which is generated by Guix itself:

#+ATTR_HTML: :style margin-left: auto; margin-right: auto;
[[http://biogems.info/cwltool-references.svg]]

Now, as a normal user, we can have the main tools installed with

: guix package -i go-ipfs

and because cwl is currently in my private tree I point the path there

: git clone https://gitlab.com/genenetwork/guix-bioinformatics.git
: env GUIX_PACKAGE_PATH=./guix-bionformatics guix package -i cwltool

If Guix is correctly intalled most packages get downloaded and
installed as binaries.  Guix only builds packages when it can not find
a binary substitute. And now I can run

: cwltool --version
: /gnu/store/nwrvpgf3l2d5pccg997cfjq2zqj0ja0j-cwltool-1.0.20181012180214/bin/.cwltool-real 1.0

Success!

Note: installing CWL requires a local git checkout until I have added
it to GNU Guix trunk. Please contact me if you want to try
earlier. Eventually all packages will get added to GNU Guix proper,
and then it becomes a simple

: guix package -i cwltool

** Choosing a CWL workflow

First I thought to run one of the pipelines from bcbio-nextgen as an
example. Bcbio generates CWL which is rather convenient. But then at
the BH18 there was a newly created CWL pipeline in
https://github.com/hacchy1983/CWL-workflows and I decided to start
from there. This particular pipeline uses github to store data and a
Docker container to run a JVM tool. Good challenge to replace that
with IPFS and Guix and make it reproducible. Note that git does
provide provenance but is not suitable for large data files. And even
though Docker may provide reproducible binary blobs - it is hard to
know what is in them, i.e., there is a trust issue, and it is usually
impossible to recreate them exactly, which is a reproducibility
issue. We can do better than that.

** Add the data sources

After above installation of go-ipfs, following [[https://docs.ipfs.io/introduction/usage/][IPFS instructions]] create a data
directory

: monza:/export/data/ipfs$ ipfs init
:  initializing IPFS node at /home/wrk/.ipfs
: generating 2048-bit RSA keypair...done
: peer identity: QmYYUMYjFELLZLwJK2YDxGFx8AeN8eQv5VnmRQA7umC5YQ

Start the daemon

: env IPFS_PATH=/export/data/ipfs ipfs daemon

and we can add the data

#+BEGIN_SRC
export IPFS_PATH=/export/data/ipfs
ipfs add -r DATA/
  added QmXwNNBT4SyWGnNogzDq8PTbtFi48Q9J6kXRWTRQGmgoNz DATA/small.ERR034597_1.fastq
  added QmcJ7P7eyMqhttSVssYhiRPUc9PxqAapVvS91Qo78xDjj3 DATA/small.ERR034597_2.fastq
  added QmfRb8TLfVnMbxauTPV2hx5EW6pYYYrCRmexcYCQyQpZjV DATA/small.chr22.fa
  added QmXaN36yNT82jQbUf2YuyV8symuF5NrdBX2hxz4mAG1Fby DATA/small.chr22.fa.amb
  added QmVM3SERieRzAdRMxpLuEKMuWT6cYkhCJsyqpGLj7qayoc DATA/small.chr22.fa.ann
  added QmfYpScLAEBXxyZmASWLJQMZU2Ze9UkV919jptGf4qm5EC DATA/small.chr22.fa.bwt
  added Qmc2P19eV77CspK8W1JZ7Y6fs2xRxh1khMsqMdfsPo1a7o DATA/small.chr22.fa.pac
  added QmV8xAwugh2Y35U3tzheZoywjXT1Kej2HBaJK1gXz8GycD DATA/small.chr22.fa.sa
  added QmR81HRaDDvvEjnhrq5ftMF1KRtqp8MiwGzwZnsC4ch1tE DATA
#+END_SRC

Test a file

: ipfs cat QmfRb8TLfVnMbxauTPV2hx5EW6pYYYrCRmexcYCQyQpZjV

and you should see the contents of small.chr22.fa. You can also browse to
http://localhost:8080/ipfs/QmR81HRaDDvvEjnhrq5ftMF1KRtqp8MiwGzwZnsC4ch1tE

Next you ought to pin the data so it does not get garbage collected by IPFS

: env IPFS_PATH=/export/data/ipfs ipfs pin add QmR81HRaDDvvEjnhrq5ftMF1KRtqp8MiwGzwZnsC4ch1tE
:   pinned QmR81HRaDDvvEjnhrq5ftMF1KRtqp8MiwGzwZnsC4ch1tE recursively

** Run CWL script

Following the instructions in the original workflow README

: cwltool Workflows/test-workflow.cwl Jobs/small.ERR034597.test-workflow.yml

complains we don't have Docker. Since we want to run without Docker specify

: cwltool --no-container Workflows/test-workflow.cwl Jobs/small.ERR034597.test-workflow.yml

Resulting in

: 'fastqc' not found: [Errno 2] No such file or directory: 'fastqc': 'fastqc'

which exists in Guix, so

: guix package -i fastqc -p ~/opt/cwl --dry-run

installs

: fastqc       0.11.5  /gnu/store/sh0wj2c00vkkh218jb5p34gndfdmbhrf-fastqc-0.11.5

after downloading

#+BEGIN_SRC
   /gnu/store/sh0wj2c00vkkh218jb5p34gndfdmbhrf-fastqc-0.11.5
   /gnu/store/0j2j0i55s0xykfcgx9fswks8792gk4sk-java-cisd-jhdf5-14.12.6-39162
   /gnu/store/bn8vb4zvdxpjl6z573bxyzqndd925x97-java-picard-1.113
   /gnu/store/g08d57f1pbi6rrzlmcaib1iyc6ir5wn9-icedtea-3.7.0
   /gnu/store/m0k3fdpgyms3fwbz24vaxclx6f1rwjdg-java-jbzip2-0.9.1
#+END_SRC

Note that the package is completely defined with its dependencies and
'content-addressable'. We can even see it pulls in Java and Picard.

After installing with Guix we can rerun the workflow and it fails at
the next step with

#+BEGIN_SRC
/gnu/store/nwrvpgf3l2d5pccg997cfjq2zqj0ja0j-cwltool-1.0.20181012180214/bin/.cwltool-real 1.0
Resolved 'Workflows/test-workflow.cwl' to 'file:///export/export/local/wrk/izip/git/opensource/cwl/hacchy1983-CWL-workflows/Workflows/test-workflow.cwl'
[workflow ] start
[workflow ] starting step qc1
[step qc1] start
[job qc1] /tmp/ig4k8x8m$ fastqc \
    -o \
    . \
    /tmp/tmp0m1p3syh/stgca222f81-6346-4abf-a005-964e80dcf783/small.ERR034597_1.fastq
Started analysis of small.ERR034597_1.fastq
Approx 5% complete for small.ERR034597_1.fastq
Approx 10% complete for small.ERR034597_1.fastq
Approx 15% complete for small.ERR034597_1.fastq
Approx 20% complete for small.ERR034597_1.fastq
...

Error: Unable to access jarfile /usr/local/share/trimmomatic/trimmomatic.jar
#+END_SRC

Success. fastqc runs fine and now we hit the next issue.  The
/usr/local points out there is at least one problem :). There is also another issue in that
the data files are specified from the source tree, e.g.

#+BEGIN_SRC yaml
fq1:  # type "File"
    class: File
    path: ../DATA/small.ERR034597_1.fastq
    format: http://edamontology.org/format_1930
#+END_SRC

Here, btw, you may start to appreciate the added value of a CWL
workflow definition. By using an EDAM ontology CWL gets metadata describing the data format which
can be used down the line. Still, we need to fetch with IPFS so the description
becomes

#+BEGIN_SRC yaml
fq1:  # type "File"
    class: File
    path: ../DATA/small.ERR034597_1.fastq
    format: http://edamontology.org/format_1930
#+END_SRC

To make sure we do not fetch the old data I moved the old data files
out of the way and modified the job description to use the IPFS local
web server

: git mv ./DATA ./DATA2
: mkdir DATA

#+BEGIN_SRC diff
--- a/Jobs/small.ERR034597.test-workflow.yml
+++ b/Jobs/small.ERR034597.test-workflow.yml
@@ -1,10 +1,10 @@
 fq1:  # type "File"
     class: File
-    path: ../DATA/small.ERR034597_1.fastq
+    path: http://localhost:8080/ipfs/QmR81HRaDDvvEjnhrq5ftMF1KRtqp8MiwGzwZnsC4ch1tE/small.ERR034597_1.fastq
     format: http://edamontology.org/format_1930
 fq2:  # type "File"
     class: File
-    path: ../DATA/small.ERR034597_2.fastq
+    path: http://localhost:8080/ipfs/QmR81HRaDDvvEjnhrq5ftMF1KRtqp8MiwGzwZnsC4ch1tE/small.ERR034597_2.fastq
     format: http://edamontology.org/format_1930
 fadir:  # type "Directory"
     class: Directory
#+END_SRC

The http fetches can be replaced later with a direct IPFS call which
will fetch files transparently from the public IPFS somewhere - much
like bittorrent does - and cache locally. We will need to add that
support to CWL so we can write something like

: path: ipfs://QmR81HRaDDvvEjnhrq5ftMF1KRtqp8MiwGzwZnsC4ch1tE

This is safe because IPFS is content-addressable.

Now the directory tree looks like

#+BEGIN_SRC
tree
.
├── DATA
├── DATA2
│   ├── small.chr22.fa
│   ├── small.chr22.fa.amb
│   ├── small.chr22.fa.ann
│   ├── small.chr22.fa.bwt
│   ├── small.chr22.fa.pac
│   ├── small.chr22.fa.sa
│   ├── small.ERR034597_1.fastq
│   └── small.ERR034597_2.fastq
├── Jobs
│   ├── small.chr22.bwa-index.yml
│   └── small.ERR034597.test-workflow.yml
├── LICENSE
├── README.md
├── small.ERR034597_1_fastqc.html
├── Tools
│   ├── bwa-index.cwl
│   ├── bwa-mem-PE.cwl
│   ├── fastqc.cwl
│   ├── samtools-sam2bam.cwl
│   └── trimmomaticPE.cwl
└── Workflows
    └── test-workflow.cwl
#+END_SRC

and CWL runs up to

: ILLUMINACLIP:/usr/local/share/trimmomatic/adapters/TruSeq2-PE.fa:2:40:15
: Error: Unable to access jarfile /usr/local/share/trimmomatic/trimmomatic.jar

** Adding a binary blob to GNU Guix

Guix likes things to be built from source - it is a clear goal of the
GNU project and the whole system is designed around that. But you can
still stick in binary blobs if you want. Main thing is that they need
to be in the /gnu/store to be seen at build time. Here I am going to
show you how to do that, but keep in mind that for reproducible
pipelines this is a questionable design choice. Much of reproducible
science is about transparancy - and binary blobs do not cut
it. Anything that is not transparent ought to be questioned.

** Replacing the binary blob with a source build

tbd

** Run the workflow inside an isolated container without network

To really make sure no dependencies 'bleed' in and no data gets pulled
from the network we can run the workflow inside a container with no
other tools than those defined in the Guix dependency graph. In
addition the container can block the network.

** Prove results are deterministic

tbd

** Capture the provenance graph

tbd

** Discussion

Here we show the principle of a working reproducible pipeline. With
little effort, anywone can create such a pipeline using GNU Guix, an
addressable data source, and a CWL work flow definition that includes
content-addressable references to software and data inputs (here we
used IPFS for data). By running the workflow multiple times it can be
asserted the outcome is deterministic and therefore reproducible.

Determinism (and reproducibility) may break when the pipeline has
software that does not behave well. Some tools give different results
when run with the exact same inputs. The solution is to fix or avoid
that software. Also, software may try to download inputs which can
lead to different results over time (for example by including a time
stamp in the output). To be stringent, it may be advisable to disable
network traffic when the workflow is running, e.g., with FIXME.

To guarantee reproducibility it is necessary to fixate inputs and have
well behaved software. With rogue or badly behaved software this may
be a challenge.  The good news is that such behaviour is not so common
and, if so, GNU Guix + IPFS will bring out any reproducibility issues.

* Extra notes

** Building cwltool inside a Guix container

Guix containers allow isolation of the build system

: env GUIX_PACKAGE_PATH=~/izip/git/opensource/genenetwork/guix-bioinformatics/ ~/izip/git/opensource/genenetwork/guix-monza/pre-inst-env guix environment -C guix --ad-hoc cwltool coreutils python

Run the tests with

: python3 setup.py build

Some network related tests may fail (6 at this point). To build CWL in a container
you can do something like this:

: env PYTHONPATH=here/lib/python3.6/site-packages:$PYTHONPATH python3 setup.py install --prefix here

** Create dependency graph

The full [[http://biogems.info/cwltool-references.pdf][package graph]] can be generated with

: env GUIX_PACKAGE_PATH=~/izip/git/opensource/genenetwork/guix-bioinformatics ./pre-inst-env guix graph cwltool |dot -Tpdf > cwltool-package.pdf

And the full [[http://biogems.info/cwltool-package.pdf][dependency graph]] can be generated with

: env GUIX_PACKAGE_PATH=~/izip/git/opensource/genenetwork/guix-bioinformatics ./pre-inst-env guix graph  --type=references cwltool |dot -Tpdf > cwltool-references.pdf

** Create a Docker container

tbd
